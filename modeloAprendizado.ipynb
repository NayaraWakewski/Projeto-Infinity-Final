{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PROJETO DE ENCERRAMENTO DE CURSO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **ALUNA:** NAYARA BRITO ALMEIDA VALEVSKII  |  **TURMA:** 109  |  **CURSO:** DATA SCIENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O PROJETO CONSISTE EM ANALISAR DUAS BASES DE DADOS DO TWITTER, DO PRESIDENTE LUIZ INÁCIO LULA DA SILVA E DO EX-PRESIDENTE JAIR MESSIAS BOLSONARO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBJETIVO:** \n",
    "- Criar um modelo de aprendizado de máquina para identificar se um tweet foi feito por Jair Bolsonaro (direita) ou Luiz Inácio Lula da Silva (esquerda), com base nas informações coletadas dos DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CRIANDO UM MODELO DE APRENDIZADO DE MAQUINA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Foi proposto um DESAFIO de criar um modelo de aprendizado de maquina, que fosse capaz de identificar se uma \"fala\", \"texto\", seria de orientação política de ESQUERDA ou DIREITA, com base nos dataframe do Presidente Lula e do Ex-Presidente Bolsonaro.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **LULA (ESQUERDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **BOLSONARO (DIREITA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTAÇÃO DAS BIBLIOTECAS.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Importa a biblioteca pandas com um alias 'pd', frequentemente usada para manipulação e análise de dados tabulares.\n",
    "from sklearn.model_selection import train_test_split #Importa o Módulo do scikit-learn para seleção de modelos e avaliação de desempenho.\n",
    "from sklearn.feature_extraction.text import CountVectorizer #Importa o Módulo para extração de características de texto para modelos de aprendizado de máquina.\n",
    "from sklearn.naive_bayes import MultinomialNB #Importa o Módulo para implementação de algoritmos de classificação Naive Bayes.\n",
    "from sklearn.metrics import accuracy_score #Importa o Módulo para métricas de avaliação de modelos de aprendizado de máquina, como acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LENDO OS ARQUIVOS E CRIANDO O DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo arquivos\n",
    "df_bolsonaro = pd.read_json('jairbolsonaro.json')\n",
    "df_lula = pd.read_json('LulaOficial.json')\n",
    "\n",
    "\n",
    "#Criando dataframe\n",
    "df = [df_bolsonaro, df_lula]\n",
    "nome = ['bolsonaro', 'lula']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O CÓDIGO ABAIXO COMBINA OS DATAFRAMES DF_LULA E DF_BOLSONARO EM UM ÚNICO DATAFRAME CHAMADO DF, UTILIZANDO A FUNÇÃO PD.CONCAT(). O ARGUMENTO IGNORE_INDEX=True REINDEXA AS LINHAS DO NOVO DATAFRAME RESULTANTE, GARANTINDO UMA INDEXAÇÃO CONTÍNUA. ISSO CRIA UM ÚNICO CONJUNTO DE DADOS QUE INCLUI INFORMAÇÕES DE AMBOS OS DATAFRAMES FILTRADOS, FACILITANDO A ANÁLISE CONJUNTA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_lula, df_bolsonaro], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINE AS CLASSES (RÓTULOS) PARA OS TWEETS ATRAVÉS DA CRIAÇÃO DE UMA COLUNA 'CLASS' NO DATAFRAME 'DF', ATRIBUINDO 'ESQUERDA' PARA OS TWEETS DE LULA E 'DIREITA' PARA OS TWEETS DE BOLSONARO.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = ['esquerda'] * len(df_lula) + ['direita'] * len(df_bolsonaro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIVIDE O DATAFRAME EM CONJUNTOS DE TREINAMENTO E TESTE UTILIZANDO A FUNÇÃO train_test_split() DA BIBLIOTECA sklearn.model_selection. OS ARRANJOS X_train E y_train CONTERÃO OS DADOS DE TREINAMENTO, ENQUANTO X_test E y_test CONTERÃO OS DADOS DE TESTE. O ARGUMENTO test_size=0.2 ESPECIFICA A PROPORÇÃO DE DADOS PARA O CONJUNTO DE TESTE, E random_state=42 DEFINE UMA SEMENTE PARA ALEATORIEDADE, ASSEGURANDO REPRODUTIBILIDADE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['full_text'], df['class'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CRIA UMA MATRIZ DE FREQUÊNCIA DE PALAVRAS UTILIZANDO O CountVectorizer DA BIBLIOTECA sklearn.feature_extraction.text. OS ARRANJOS X_train_vectorized E X_test_vectorized CONTÊM AS REPRESENTAÇÕES VETORIAIS DAS PALAVRAS NOS CONJUNTOS DE TREINAMENTO E TESTE, RESPECTIVAMENTE. O vetorizador É AJUSTADO AOS DADOS DE TREINAMENTO COM fit_transform() E APLICADO AOS DADOS DE TESTE COM transform().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TREINE UM MODELO NAIVE BAYES UTILIZANDO O MultinomialNB() DA BIBLIOTECA sklearn.naive_bayes. O MODELO É TREINADO NOS DADOS DE TREINAMENTO REPRESENTADOS PELA MATRIZ DE FREQUÊNCIA DE PALAVRAS X_train_vectorized E SUAS RESPECTIVAS CLASSES y_train COM O MÉTODO fit().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REALIZE PREVISÕES NO CONJUNTO DE TESTE UTILIZANDO O MODELO TREINADO COM O MÉTODO predict(). AS PREDIÇÕES SÃO ARMAZENADAS NA VARIÁVEL 'predictions'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CALCULE A ACURÁCIA DO MODELO UTILIZANDO A FUNÇÃO accuracy_score() DA BIBLIOTECA sklearn.metrics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 0.94\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Acurácia do modelo: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TESTANDO O MODELO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">O CÓDIGO DEMONSTRA A UTILIZAÇÃO DO MODELO TREINADO PARA FAZER PREVISÕES EM NOVOS TWEETS. OS TWEETS SÃO REPRESENTADOS VETORIALMENTE E AS CLASSES PREDITAS SÃO IMPRESSAS PARA CADA TWEET.\n",
    "\n",
    ">NESTE EXEMPLO, O MODELO FAZ PREVISÕES SOBRE A CLASSE (RÓTULO) POLÍTICA DE CADA TWEET COM BASE NAS PALAVRAS UTILIZADAS NOS TEXTOS. CADA TWEET É ASSOCIADO A UMA CLASSE PREVISTA, QUE PODE SER \"ESQUERDA\" OU \"DIREITA\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Vamos lutar por um Brasil melhor!\n",
      "Predicted Class: esquerda\n",
      "\n",
      "Tweet: Sou contra a familia tradicional pois essa é uma instituicao falida\n",
      "Predicted Class: esquerda\n",
      "\n",
      "Tweet: Sou a favor da familia tradicional, pois ensina boas condutas\n",
      "Predicted Class: direita\n",
      "\n",
      "Tweet: Segurança pública é nossa prioridade.\n",
      "Predicted Class: direita\n",
      "\n",
      "Tweet: Trabalho e emprego para todos\n",
      "Predicted Class: esquerda\n",
      "\n",
      "Tweet: Liberdade economica para o pais\n",
      "Predicted Class: direita\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de previsão\n",
    "new_tweets = [\n",
    "    \"Vamos lutar por um Brasil melhor!\",\n",
    "    \"Sou contra a familia tradicional pois essa é uma instituicao falida\",\n",
    "    \"Sou a favor da familia tradicional, pois ensina boas condutas\",\n",
    "    \"Segurança pública é nossa prioridade.\",\n",
    "    \"Trabalho e emprego para todos\",\n",
    "    \"Liberdade economica para o pais\"\n",
    "]\n",
    "\n",
    "new_tweets_vectorized = vectorizer.transform(new_tweets)\n",
    "predicted_classes = model.predict(new_tweets_vectorized)\n",
    "\n",
    "for tweet, predicted_class in zip(new_tweets, predicted_classes):\n",
    "    print(f'Tweet: {tweet}')\n",
    "    print(f'Predicted Class: {predicted_class}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
