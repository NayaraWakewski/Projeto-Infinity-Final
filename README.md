# Projeto Infinity Curso Data Science - Encerramento
Projeto Final de Encerramento do Curso de Data Science da Infinity School

![texto alt](https://cdn.eadplataforma.app/client/infinityschool/upload/others/e993f6d822d15efdb3585d1b733e4020.png)


# An√°lise de Dados dos Twitters do Presidente Lula e Ex-Presidente Bolsonaro.

Este √© um reposit√≥rio que cont√©m informa√ß√µes e ferramentas para an√°lise de dados e a constru√ß√£o de um Modelo de Aprendizado de Maquina. Esse projeto faz parte do encerramento do Curso de Data Science da Infinity School.


## ‚öôÔ∏è Instalando as Bibliotecas necess√°rias.

**Importando as Bibliotecas**: Nesta etapa, importamos as bibliotecas necess√°rias para execu√ß√£o do Projeto. Trabalharemos com: 

**pandas as pd:** Para manipula√ß√£o e an√°lise de dados tabulares.

**matplotlib.pyplot as plt:** Para cria√ß√£o de visualiza√ß√µes gr√°ficas.

**datetime:** Para manipula√ß√£o de datas e hor√°rios.

**nltk:** Para processamento de linguagem natural.

**nltk.corpus.stopwords:** Lista de palavras irrelevantes (stop words) da NLTK.

**nltk.tokenize.word_tokenize:** Para dividir um texto em palavras individuais (tokeniza√ß√£o).

**re:** Para trabalhar com express√µes regulares e padr√µes de texto.

**wordcloud.WordCloud:** Para gerar nuvens de palavras.

**collections.Counter:** Para contar elementos em uma cole√ß√£o.

**plotly.express as px:** Para criar visualiza√ß√µes interativas.

**plotly.offline as pyo:** √© um m√≥dulo da biblioteca Plotly que permite criar gr√°ficos interativos e visualiza√ß√µes utilizando Python, que podem ser exibidos diretamente no ambiente local, sem a necessidade de uma conex√£o com a internet.

Al√©m disso, h√° o uso de fun√ß√µes nltk.download() para fazer o download de recursos espec√≠ficos do NLTK, como a lista de stop words e o tokenizador.


## üöÄ Come√ßando - AN√ÅLISE DE DADOS.

Nesta primeira parte do projeto, realizamos a an√°lise de dados dos Twitters do Presidente Lula e do Ex-Presidente Bolsonaro. O objetivo √© extrair alguns insights a partir desses dados e identificando tend√™ncias.

1. **Dataframe**: Ap√≥s a instala√ß√£o das bibliotecas importamos os arquivos JSON 'LulaOficial.json' e 'jairbolsonaro.json' e transformamos em dataframe.

2. **Formatando a coluna de DATA**: Para uma melhor an√°lise de dados, formatamos a coluna data, tanto a nivel de formata√ß√£o, como para o tipo datetime.

3. **Selecionando as Colunas para An√°lises**: Nesta etapa, selecionamos apenas colunas importantes para este projeto, que foram: ['created_at', 'full_text', 'display_text_range', 'favorite_count', 'retweet_count'].

4. **Contagem Total dos Twitters**: Esta an√°lise realiza a contagem total de tweets ao longo do tempo, bem como a m√©dia de retweets e favoritos para os pol√≠ticos Lula e Bolsonaro. Ele converte as colunas 'created_at' em objetos de data e hora, contabiliza o n√∫mero de tweets por m√™s para cada pol√≠tico, calcula as m√©dias de retweets e favoritos para ambos os pol√≠ticos e imprime os resultados.
O resultado final inclui a contagem total de tweets por m√™s para Lula e Bolsonaro, seguido das m√©dias de retweets e favoritos para cada um deles. S√£o gerado gr√°ficos e o c√≥digo usa plt.tight_layout() para garantir uma boa distribui√ß√£o dos subplots e, em seguida, plt.show() para exibir os gr√°ficos. Isso permite visualizar as tend√™ncias ao longo do tempo na contagem de tweets e comparar as m√©dias de retweets e favoritos entre os pol√≠ticos Lula e Bolsonaro.

5. **An√°lise de Dados (Engajamento Twitter) - GR√ÅFICO DE LINHAS**: Essa etapa calcula o engajamento (soma de retweets e favoritos) para os pol√≠ticos Lula e Bolsonaro, cria um DataFrame consolidado para o gr√°fico, converte a coluna 'created_at' para datetime, filtra os dados por um intervalo de datas espec√≠fico, cria um gr√°fico interativo de linha comparando o engajamento ao longo do tempo e, finalmente, salva o gr√°fico como um arquivo HTML.
Ele √© focado em calcular, visualizar e comparar o engajamento dos pol√≠ticos Lula e Bolsonaro no Twitter ao longo de um intervalo de datas espec√≠fico. O gr√°fico interativo de linha mostra as tend√™ncias de engajamento ao longo do tempo para cada pol√≠tico.

![grafico](https://user-images.githubusercontent.com/79403619/261483127-28963a34-b726-446e-9acd-5eded296af17.png)

6. **An√°lise de Dados (Engajamento Twitter) - GR√ÅFICO DE BARRAS**: Essa etapa calcula o engajamento (soma de retweets e favoritos) para os pol√≠ticos Lula e Bolsonaro, cria um DataFrame consolidado para o gr√°fico, agrupa os dados por per√≠odo e pol√≠tico, gera um gr√°fico de barras din√¢mico comparando o engajamento ao longo do tempo e salva o gr√°fico como um arquivo HTML.
O c√≥digo foca na an√°lise comparativa do engajamento dos pol√≠ticos Lula e Bolsonaro ao longo do tempo, utilizando um gr√°fico de barras din√¢mico para visualizar as diferen√ßas no engajamento mensal entre os pol√≠ticos.

![grafico2](https://user-images.githubusercontent.com/79403619/261483149-73fd1242-ac3f-453f-95fc-dc20148c1825.png)

7. **An√°lise de Dados (Engajamento Twitter) - GR√ÅFICO DE DISPERS√ÉO**: Essa etapa cria um DataFrame consolidado para o gr√°fico de dispers√£o, define um intervalo de datas para filtrar os dados, gera um gr√°fico de dispers√£o que mostra a rela√ß√£o entre retweets e favoritos com a data e o filtro aplicados, e exibe o gr√°fico utilizando a fun√ß√£o pyo.plot. O objetivo principal √© visualizar a rela√ß√£o entre retweets e favoritos para os pol√≠ticos Lula e Bolsonaro, considerando um intervalo de datas espec√≠fico. O gr√°fico de dispers√£o ajuda a identificar padr√µes ou tend√™ncias entre as m√©tricas de engajamento.

![grafico3](https://user-images.githubusercontent.com/79403619/261483170-f734529b-f02c-49b8-b31f-1e9bda6399fa.png)

8. **An√°lise de Dados (Palavras mais Faladas)**: Nessa etapa criei um DataFrame consolidado para processamento de texto a partir dos tweets de Lula e Bolsonaro. Realizando o pr√©-processamento do texto usando a biblioteca NLTK, incluindo a convers√£o para min√∫sculas, remo√ß√£o de URLs, hashtags, pontua√ß√£o e stopwords. Em seguida, calcula a frequ√™ncia das palavras mais faladas para Lula e Bolsonaro, calcula o percentual dessas palavras em rela√ß√£o ao total de palavras, e finalmente, gera um gr√°fico de barras comparando o percentual das palavras mais faladas para ambos os pol√≠ticos.
O objetivo √© identificar as palavras mais frequentes nos tweets de Lula e Bolsonaro, permitindo uma an√°lise superficial das principais palavras utilizadas por cada pol√≠tico. O gr√°fico de barras apresenta visualmente o percentual das palavras mais faladas para ambos.

![analise](https://user-images.githubusercontent.com/79403619/261483066-5bc04a5f-0c81-412c-baf8-0d97451327ca.png)


9. **Nuvem de Palavras** Nessa etapa estamos criando um c√≥digo onde √© gerado uma nuvem de palavras para os tweets dos pol√≠ticos Lula e Bolsonaro. Utiliza a biblioteca WordCloud para gerar a nuvem de palavras com base nas frequ√™ncias das palavras nos tweets. O gr√°fico resultante mostra a nuvem de palavras para os tweets dos pol√≠ticos Lula e Bolsonaro.
O objetivo √© visualizar de forma gr√°fica as palavras mais frequentes nos tweets, destacando as palavras que s√£o mais utilizadas.

> Lula
![output_LULA](https://github.com/NayaraWakewski/Projeto-Infinity-Final-Curso/assets/79403619/960696ab-45f6-4d94-b864-8e0dbff235b6)

> Bolsonaro
![output_bolsonaro](https://github.com/NayaraWakewski/Projeto-Infinity-Final-Curso/assets/79403619/05f83dec-4ed7-4b2b-95b2-452d79a5c9e6)


10. **An√°lise de uma data espec√≠fica (Hist√≥rica)**: Afim de acrescentarmos informa√ß√µes no projeto, decidi criar um c√≥digo para analisar o que foi postado por ambos, em uma data espec√≠fica hist√≥rica.  

**Ao seguir essas etapas, buscamos obter uma compreens√£o aprofundada dos dados fornecidos, lembrando que a inten√ß√£o da An√°lise √© n√£o ter nenhum vies pol√≠tico.**


## üöÄ MODELO DE APRENDIZADO DE MAQUINA.

**Criando um C√≥digo de Aprendizado de Maquina**: Foi proposto um DESAFIO de criar um modelo de aprendizado de maquina, que fosse capaz de identificar se uma "fala", "texto", seria de orienta√ß√£o pol√≠tica de **ESQUERDA** ou **DIREITA**, com base nos dataframe do Presidente Lula e do Ex-Presidente Bolsonaro. 

A acur√°cia do modelo ficou em 94%. E ap√≥s a cria√ß√£o do modelo foi feita uma etapa de teste, para avalia√ß√£o. Conforme print abaixo:

![teste](https://user-images.githubusercontent.com/79403619/261483086-df4c660b-8ce7-4ecc-a467-2498be712eb2.jpg)

   
### üõ†Ô∏è Instala√ß√£o/Ferramentas

> **Para elabora√ß√£o do Projeto utilizamos as seguintes ferramentas:**

- **Visual Studio Code** - utilizado para organizar as etapas do projeto, testar as query em Sql e fazer o projeto em Python.
- **Github** - Plataforma de hospedagem de c√≥digo, que utilizamos para subir o projeto.



## ‚öôÔ∏è Exemplo c√≥digo Python do Aprendizado de M√°quina em Python:


- **Importando Bibliotecas**

```python:

#Importando Bibliotecas
import pandas as pd #Importa a biblioteca pandas com um alias 'pd', frequentemente usada para manipula√ß√£o e an√°lise de dados tabulares.
from sklearn.model_selection import train_test_split #Importa o M√≥dulo do scikit-learn para sele√ß√£o de modelos e avalia√ß√£o de desempenho.
from sklearn.feature_extraction.text import CountVectorizer #Importa o M√≥dulo para extra√ß√£o de caracter√≠sticas de texto para modelos de aprendizado de m√°quina.
from sklearn.naive_bayes import MultinomialNB #Importa o M√≥dulo para implementa√ß√£o de algoritmos de classifica√ß√£o Naive Bayes.
from sklearn.metrics import accuracy_score #Importa o M√≥dulo para m√©tricas de avalia√ß√£o de modelos de aprendizado de m√°quina, como acur√°cia.

#Combinando dataframes.
df = pd.concat([df_lula, df_bolsonaro], ignore_index=True)

#Definindo Classe e R√≥tulos
df['class'] = ['esquerda'] * len(df_lula) + ['direita'] * len(df_bolsonaro)

#Dividindo o Dataframe
X_train, X_test, y_train, y_test = train_test_split(df['full_text'], df['class'], test_size=0.2, random_state=42)

#Criando uma matriz de frequencia.
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

#Treinando um Modelo
model = MultinomialNB()
model.fit(X_train_vectorized, y_train)

#Previs√£o
predictions = model.predict(X_test_vectorized)

#Acur√°cia do Modelo
accuracy = accuracy_score(y_test, predictions)
print(f'Acur√°cia do modelo: {accuracy:.2f}')
```


## üéÅ Express√µes de gratid√£o

* Compartilhe com outras pessoas esse projeto üì¢;
* Quer saber mais sobre o projeto? Entre em contato para tomarmos um :coffee:;
* Leia a Newsletter no Linkedin Miaudados (Assinar no LinkedIn https://www.linkedin.com/build-relation/newsletter-follow?entityUrn=7084687709755043840)

---
‚å®Ô∏è com ‚ù§Ô∏è por [Nayara Vakevskii](https://github.com/NayaraWakewski) (https://www.linkedin.com/in/nayaraba/) üòä
